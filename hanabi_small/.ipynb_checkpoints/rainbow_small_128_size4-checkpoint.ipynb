{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017a78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from pettingzoo.classic import hanabi_v4\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tianshou.data import Collector, PrioritizedVectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import (\n",
    "    BasePolicy,\n",
    "    RainbowPolicy,\n",
    "    MultiAgentPolicyManager,\n",
    "    RandomPolicy,\n",
    ")\n",
    "from tianshou.utils.net.discrete import NoisyLinear\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils import TensorboardLogger\n",
    "from tianshou.utils.net.common import Net\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of rainbow used in deepmind paper\n",
    "p = {\n",
    "    'hidden_layers': [128,128],\n",
    "    'gamma': 0.99,\n",
    "    'lr': 1e-4,\n",
    "    'target_update_freq': 500,\n",
    "    'estimation_steps': 1,\n",
    "    'num_train':32,\n",
    "    'num_test':32,\n",
    "    'buffer_size':50000,\n",
    "    'vmax':25,\n",
    "    'vmin':-25,\n",
    "    'noisy_std':0.1,\n",
    "    'atom_size':51,\n",
    "    'minimum_replay_history':512,\n",
    "    'batch_size':32,\n",
    "    'steps_per_collect': 10016,\n",
    "    'updates_per_train':1563,\n",
    "    'test_steps': 20000,\n",
    "    'epochs':5000,\n",
    "    'eps_decay_period': 100,\n",
    "    'test_frequency': 3,\n",
    "    'test_eps': 0,\n",
    "    'save_frequency': 25,\n",
    "    'eps_final':0.01,\n",
    "    'adam_eps': 3.125e-5,\n",
    "    'path': 'results/hanabi_small_128_size4/',\n",
    "    'lr_scheduler_factor': 0.1,\n",
    "    'lr_scheduler_patience': 20\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1b13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(render_mode=None):\n",
    "    return PettingZooEnv(hanabi_v4.env(colors=2, ranks=5, players=2, hand_size=4, max_information_tokens=3,\n",
    "max_life_tokens=1, observation_type=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14b47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents(p):\n",
    "    \n",
    "    def noisy_linear(x, y):\n",
    "        return NoisyLinear(x, y, p['noisy_std'])\n",
    "    \n",
    "    # Return Policy, Agents, Envs\n",
    "    env = get_env()\n",
    "    observation_space = env.observation_space['observation'] if isinstance(\n",
    "    env.observation_space, gym.spaces.Dict\n",
    "    ) else env.observation_space\n",
    "\n",
    "    state_shape = observation_space.shape or observation_space.n\n",
    "    action_shape = env.action_space.shape or env.action_space.n\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = Net(\n",
    "            state_shape,\n",
    "            action_shape,\n",
    "            hidden_sizes=p['hidden_layers'],\n",
    "            device = device,\n",
    "            softmax = True,\n",
    "            num_atoms = p['atom_size'],\n",
    "            dueling_param = ({\n",
    "                'linear_layer': noisy_linear\n",
    "            }, {\n",
    "                'linear_layer': noisy_linear})\n",
    "    )\n",
    "\n",
    "    optim = torch.optim.Adam(net.parameters(), lr= p['lr'], eps=p['adam_eps'])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode = 'max', factor = p['lr_scheduler_factor'],\n",
    "                                                              patience = p['lr_scheduler_patience'])\n",
    "\n",
    "    agent = RainbowPolicy(\n",
    "            net,\n",
    "            optim,\n",
    "            p['gamma'],\n",
    "            num_atoms = p['atom_size'],\n",
    "            v_min = p['vmin'],\n",
    "            v_max = p['vmax'],\n",
    "            estimation_step = p['estimation_steps'],\n",
    "            target_update_freq=p['target_update_freq']\n",
    "        ).to(device)\n",
    "\n",
    "    agents = [agent, agent]\n",
    "    policy = MultiAgentPolicyManager(agents, env)\n",
    "    agents = env.agents\n",
    "\n",
    "    train_envs = DummyVectorEnv([get_env for _ in range(p['num_train'])])\n",
    "    test_envs = DummyVectorEnv([get_env for _ in range(p['num_test'])])\n",
    "    \n",
    "    return policy, agents, train_envs, test_envs, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b396937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collectors(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    test_envs,\n",
    "    p\n",
    "):\n",
    "    \n",
    "    # Get collectors\n",
    "    train_collector = Collector(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    PrioritizedVectorReplayBuffer(p['buffer_size'], len(train_envs), alpha = 0.6, beta = 0.4, weight_norm=True),\n",
    "    exploration_noise=True)\n",
    "    \n",
    "    test_collector = Collector(policy, test_envs, exploration_noise=True)\n",
    "    \n",
    "    return train_collector, test_collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e1b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_buffer(\n",
    "    train_collector,\n",
    "    agents,\n",
    "    policy,\n",
    "    p\n",
    "):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(1)\n",
    "    train_collector.collect(n_step = p['minimum_replay_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13665eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_policy(policy, agents, p):\n",
    "    for a in agents:\n",
    "        torch.save(policy.policies[a].state_dict(), f'{p[\"path\"]}{a}_params.pth')\n",
    "\n",
    "def save_history(history, p):\n",
    "    np.save(f'{p[\"path\"]}training_rewards.npy', np.array(history))\n",
    "    \n",
    "def change_lr(optimizer, new_lr):\n",
    "    # Run this to change the learning rate to 1e-5:\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b85c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(iteration, p):\n",
    "    if iteration > p['eps_decay_period']:\n",
    "        return p['eps_final']\n",
    "    else:\n",
    "        gradient = (1 - p['eps_final'])/p['eps_decay_period']\n",
    "        return 1 - gradient*iteration\n",
    "        \n",
    "def set_eps(policy, agents, new_eps):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(new_eps)\n",
    "        \n",
    "def train(\n",
    "    policy,\n",
    "    train_collector,\n",
    "    test_collector,\n",
    "    agents,\n",
    "    p,\n",
    "    lr_scheduler,\n",
    "    training_history = []\n",
    "):\n",
    "\n",
    "    for i in tqdm(range(p['epochs'])):\n",
    "        \n",
    "        eps = get_eps(i, p)\n",
    "        set_eps(policy, agents, eps)\n",
    "        \n",
    "        # Collection step\n",
    "        result = train_collector.collect(n_step = p['steps_per_collect'])\n",
    "        \n",
    "        # Test Step\n",
    "        if i%p['test_frequency'] == 0:\n",
    "            set_eps(policy, agents, p['test_eps'])\n",
    "            result = test_collector.collect(n_step = p['test_steps'])\n",
    "            mean_reward = result['rews'].mean()\n",
    "            tqdm.write(str(mean_reward))\n",
    "            training_history.append(mean_reward)\n",
    "            set_eps(policy, agents, eps)\n",
    "            lr_scheduler.step(mean_reward)\n",
    "    \n",
    "        if i%p['save_frequency'] == 0:\n",
    "            save_policy(policy, agents,p)\n",
    "            save_history(training_history,p)\n",
    "            plot_and_save(training_history, p['test_frequency'],p, show = False)\n",
    "    \n",
    "        # Update step (one epoch)\n",
    "        for _ in range(p['updates_per_train']): \n",
    "            losses = policy.update(p['batch_size'], train_collector.buffer)\n",
    "    \n",
    "    plot_and_save(training_history, test_frequency)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a19b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(training_history, test_frequency, p, save = True, show = True):\n",
    "    x = np.arange(len(training_history))\n",
    "    x *= test_frequency\n",
    "    plt.plot(x, training_history)\n",
    "    plt.title('Combined Average Score (Rainbow, 2 Color game)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Score (max 10)')\n",
    "    if save: plt.savefig(f'{p[\"path\"]}training_curve.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "def load(policy, agents, p):\n",
    "    for a in agents:\n",
    "        policy.policies[a].load_state_dict(torch.load(f'{p[\"path\"]}{a}_params.pth'))\n",
    "    his = list(np.load(f'{p[\"path\"]}training_rewards.npy'))\n",
    "    return his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf68087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n",
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "policy, agents, train_envs, test_envs, lr_scheduler = get_agents(p)\n",
    "train_collector, test_collector = get_collectors(policy, train_envs, test_envs, p)\n",
    "initialize_buffer(train_collector, agents, policy, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f614d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_history = load(policy, agents,p)\n",
    "training_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c545f926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78de98a5389749bd9a7fd0cf3c4237ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0680306905370844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1485557083906465\n",
      "1.0798429319371727\n",
      "1.0242718446601942\n",
      "0.9820971867007673\n",
      "1.0026075619295958\n",
      "1.0\n",
      "0.8942558746736292\n",
      "0.5652759084791387\n",
      "0.9266666666666666\n",
      "1.0013333333333334\n",
      "1.0173333333333334\n",
      "0.9598445595854922\n",
      "1.1196172248803828\n",
      "1.009913258983891\n",
      "1.2557628979143798\n",
      "1.1671732522796352\n",
      "1.3973799126637554\n",
      "1.592938733125649\n",
      "1.6595982142857142\n",
      "1.635483870967742\n",
      "1.6512605042016806\n",
      "1.4083720930232557\n",
      "1.2828402366863905\n",
      "1.527647610121837\n",
      "1.6056818181818182\n",
      "1.4734251968503937\n",
      "1.6293478260869565\n",
      "1.7381930184804928\n",
      "1.6801181102362204\n",
      "1.6235294117647059\n",
      "1.7762605042016806\n",
      "1.845703125\n",
      "1.8577981651376148\n",
      "2.5205183585313176\n",
      "2.8986332574031892\n",
      "2.9293981481481484\n",
      "3.2121559633027523\n",
      "3.4264018691588785\n",
      "3.5201380897583427\n",
      "3.6144721233689205\n",
      "3.7016317016317015\n",
      "3.8053927315357563\n",
      "3.775147928994083\n",
      "3.8611435239206533\n",
      "3.947429906542056\n",
      "3.855039637599094\n",
      "3.5303738317757007\n",
      "4.054761904761905\n",
      "3.9838523644752017\n",
      "3.819954128440367\n",
      "4.03066037735849\n",
      "3.510807736063709\n",
      "4.16878612716763\n",
      "4.376306620209059\n",
      "4.322093023255814\n",
      "4.342165898617512\n",
      "4.3969907407407405\n",
      "4.462232243517475\n",
      "4.491822429906542\n",
      "4.456521739130435\n",
      "4.55080831408776\n",
      "4.595596755504055\n",
      "4.577011494252874\n",
      "4.547344110854503\n",
      "4.525951557093426\n",
      "4.5147392290249435\n",
      "4.683236994219653\n",
      "4.678489702517163\n",
      "4.599770642201835\n",
      "4.623435722411831\n",
      "4.6943483275663205\n",
      "4.678121420389462\n",
      "4.569284064665127\n",
      "4.663594470046083\n",
      "4.856815578465063\n",
      "4.701612903225806\n",
      "4.745995423340961\n",
      "4.864310148232611\n",
      "4.95537757437071\n",
      "4.898285714285715\n",
      "5.005747126436781\n",
      "4.972571428571428\n",
      "4.941446613088404\n",
      "4.992045454545455\n",
      "4.770715096481271\n",
      "4.878348214285714\n",
      "5.090285714285714\n",
      "4.980725623582766\n",
      "5.1625\n",
      "5.060295790671217\n",
      "5.127683615819209\n",
      "4.848214285714286\n",
      "5.113610798650169\n",
      "5.258836944127708\n",
      "5.160775370581528\n",
      "5.119774011299435\n",
      "5.134703196347032\n",
      "5.160815402038505\n",
      "5.112128146453089\n",
      "5.217342342342342\n",
      "5.293714285714286\n",
      "5.20475113122172\n",
      "5.236301369863014\n",
      "5.257954545454545\n",
      "5.196590909090909\n",
      "5.302272727272728\n",
      "5.298876404494382\n",
      "5.245772266065389\n",
      "5.2847533632287\n",
      "5.223981900452489\n",
      "5.152099886492622\n",
      "5.306214689265537\n",
      "5.236282194848824\n",
      "5.148190045248869\n",
      "5.044419134396355\n",
      "5.136008918617614\n",
      "5.108597285067873\n",
      "5.322033898305085\n",
      "5.3031674208144794\n",
      "5.382687927107061\n",
      "5.083333333333333\n",
      "5.010044642857143\n",
      "5.418367346938775\n",
      "5.204081632653061\n",
      "5.284745762711864\n",
      "5.2735527809307605\n",
      "5.278153153153153\n",
      "5.157366071428571\n",
      "5.268841394825647\n",
      "5.3480725623582765\n",
      "5.318840579710145\n",
      "5.365384615384615\n",
      "5.249440715883669\n",
      "5.4104308390022675\n",
      "5.130777903043969\n",
      "5.374715261958998\n",
      "5.321709786276715\n",
      "5.323628219484882\n",
      "5.298876404494382\n",
      "5.198218262806236\n",
      "5.250280583613917\n",
      "5.278153153153153\n",
      "5.368539325842697\n",
      "5.242081447963801\n",
      "5.429537767756482\n",
      "5.493243243243243\n",
      "5.438556933483652\n",
      "5.529411764705882\n",
      "5.4859075535512964\n",
      "5.503378378378378\n",
      "5.468714448236632\n",
      "5.481941309255079\n",
      "5.495495495495495\n",
      "5.522083805209513\n",
      "5.4813137032842585\n",
      "5.551412429378531\n",
      "5.584269662921348\n",
      "5.517593643586833\n",
      "5.4324324324324325\n",
      "5.543083900226757\n",
      "5.51457399103139\n",
      "5.528280542986425\n",
      "5.556179775280899\n",
      "5.550282485875706\n",
      "5.511261261261262\n",
      "5.523809523809524\n",
      "5.502257336343115\n",
      "5.489289740698985\n",
      "5.5157657657657655\n",
      "5.552927927927928\n",
      "5.590293453724605\n",
      "5.507900677200903\n",
      "5.487640449438202\n",
      "5.579661016949153\n",
      "5.538720538720539\n",
      "5.574803149606299\n",
      "5.543526785714286\n",
      "5.581157775255392\n",
      "5.600225225225225\n",
      "5.574635241301908\n",
      "5.526674233825199\n",
      "5.6072234762979685\n",
      "5.578947368421052\n",
      "5.553047404063205\n",
      "5.641573033707865\n",
      "5.564044943820225\n",
      "5.558456299659478\n",
      "5.595480225988701\n",
      "5.552927927927928\n",
      "5.551020408163265\n",
      "5.577702702702703\n",
      "5.588963963963964\n",
      "5.578828828828829\n",
      "5.556179775280899\n",
      "5.4696629213483146\n",
      "5.559910414333706\n",
      "5.54054054054054\n",
      "5.576099210822999\n",
      "5.556306306306307\n",
      "5.502818489289741\n",
      "5.604519774011299\n",
      "5.52572706935123\n",
      "5.6022598870056495\n",
      "5.6015625\n",
      "5.602708803611738\n",
      "5.581369248035915\n",
      "5.575112107623318\n",
      "5.563986409966025\n",
      "5.556805399325085\n",
      "5.583802024746906\n",
      "5.618510158013544\n",
      "5.6223224351747465\n",
      "5.61030235162374\n",
      "5.591882750845547\n",
      "5.528216704288939\n",
      "5.5887640449438205\n",
      "5.611990950226244\n",
      "5.588963963963964\n",
      "5.604284103720405\n",
      "5.579302587176603\n",
      "5.652076318742985\n",
      "5.5636978579481395\n",
      "5.595264937993235\n",
      "5.598194130925508\n",
      "5.607865168539326\n",
      "5.560948081264108\n",
      "5.613303269447576\n",
      "5.533783783783784\n",
      "5.61123595505618\n",
      "5.627118644067797\n",
      "5.607666290868095\n",
      "5.581081081081081\n",
      "5.614349775784754\n",
      "5.586636466591166\n",
      "5.657687991021325\n",
      "5.606334841628959\n",
      "5.631756756756757\n",
      "5.554678692220969\n",
      "5.62247191011236\n",
      "5.658013544018059\n",
      "5.6422947131608545\n",
      "5.608793686583991\n",
      "5.510112359550562\n",
      "5.641891891891892\n",
      "5.634009009009009\n",
      "5.601809954751131\n",
      "5.537598204264871\n",
      "5.6072234762979685\n",
      "5.53490990990991\n",
      "5.5984251968503935\n",
      "5.544431946006749\n",
      "5.594594594594595\n",
      "5.572077185017026\n",
      "5.585972850678733\n",
      "5.637178051511758\n",
      "5.6265466816647915\n",
      "5.60972850678733\n",
      "5.599322799097066\n",
      "5.608548931383577\n",
      "5.6\n",
      "5.532657657657658\n",
      "5.602491506228765\n",
      "5.574492099322799\n",
      "5.565952649379932\n",
      "5.634009009009009\n",
      "5.620067643742954\n",
      "5.6139954853273135\n",
      "5.6275395033860045\n",
      "5.606981981981982\n",
      "5.606779661016949\n",
      "5.598876404494382\n",
      "5.650507328072154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_195097/3111622494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_collector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_collector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_195097/3434042788.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(policy, train_collector, test_collector, agents, p, lr_scheduler, training_history)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Collection step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steps_per_collect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Test Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/data/collector.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, n_step, n_episode, random, render, no_grad, gym_reset_kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0maction_remap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;31m# step in env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_remap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mready_env_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mobs_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/env/venvs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, id)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/env/worker/dummy.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, action, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/env/pettingzoo_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    111\u001b[0m     ) -> Union[Tuple[Dict, List[int], bool, Dict], Tuple[Dict, List[int], bool, bool,\n\u001b[1;32m    112\u001b[0m                                                          Dict]]:\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Here, we do not label the return values explicitly to keep compatibility with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pettingzoo/utils/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pettingzoo/utils/wrappers/base.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pettingzoo/utils/wrappers/assert_out_of_bounds.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         ), \"action is not in action space\"\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pettingzoo/utils/wrappers/base.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pettingzoo/utils/wrappers/terminate_illegal.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pettingzoo/utils/wrappers/base.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pettingzoo/classic/hanabi/hanabi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, observe, as_vector)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;31m# Apply action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mall_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhanabi_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# Update internal state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hanabi_learning_environment/rl_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeal_random_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_observation_all_players\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# Reward is score differential. May be large and negative at game end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hanabi_learning_environment/rl_env.py\u001b[0m in \u001b[0;36m_make_observation_all_players\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \"\"\"\n\u001b[1;32m    374\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     player_observations = [self._extract_dict_from_backend(\n\u001b[0m\u001b[1;32m    376\u001b[0m         player_id, self.state.observation(player_id))\n\u001b[1;32m    377\u001b[0m         for player_id in range(self.players)]  # pylint: disable=bad-continuation\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hanabi_learning_environment/rl_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \"\"\"\n\u001b[1;32m    374\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     player_observations = [self._extract_dict_from_backend(\n\u001b[0m\u001b[1;32m    376\u001b[0m         player_id, self.state.observation(player_id))\n\u001b[1;32m    377\u001b[0m         for player_id in range(self.players)]  # pylint: disable=bad-continuation\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hanabi_learning_environment/rl_env.py\u001b[0m in \u001b[0;36m_extract_dict_from_backend\u001b[0;34m(self, player_id, observation)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m# ipdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0mobs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vectorized\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0mobs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pyhanabi\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hanabi_learning_environment/pyhanabi.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0;31m# Canonical observations are bit strings, so it is ok to encode using a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# string. For float or double observations, make a custom object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m     \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoding_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hanabi_learning_environment/pyhanabi.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0;31m# Canonical observations are bit strings, so it is ok to encode using a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# string. For float or double observations, make a custom object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m     \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoding_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(policy, train_collector, test_collector, agents, p, lr_scheduler, training_history = training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73832f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c9945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a02f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
