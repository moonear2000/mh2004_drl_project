{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "017a78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from pettingzoo.classic import hanabi_v4\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tianshou.data import Collector, PrioritizedVectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import (\n",
    "    BasePolicy,\n",
    "    RainbowPolicy,\n",
    "    MultiAgentPolicyManager,\n",
    "    RandomPolicy,\n",
    ")\n",
    "from tianshou.utils.net.discrete import NoisyLinear\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils import TensorboardLogger\n",
    "from tianshou.utils.net.common import Net\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of rainbow used in deepmind paper\n",
    "p = {\n",
    "    'hidden_layers': [128,128],\n",
    "    'gamma': 0.99,\n",
    "    'lr': 1e-4,\n",
    "    'target_update_freq': 500,\n",
    "    'estimation_steps': 1,\n",
    "    'num_train':32,\n",
    "    'num_test':16,\n",
    "    'buffer_size':50000,\n",
    "    'vmax':25,\n",
    "    'vmin':-25,\n",
    "    'noisy_std':0.1,\n",
    "    'atom_size':51,\n",
    "    'minimum_replay_history':500,\n",
    "    'batch_size':32,\n",
    "    'steps_per_collect': 4,\n",
    "    'updates_per_train': 1,\n",
    "    'test_steps': 10000,\n",
    "    'epochs':int(10e6),\n",
    "    'eps_decay_period': 20000,\n",
    "    'test_frequency': 1000,\n",
    "    'test_eps': 0,\n",
    "    'save_frequency': 10000,\n",
    "    'eps_final':0.01,\n",
    "    'adam_eps': 3.125e-5,\n",
    "    'path': 'results/hanabi_small_128_size2/',\n",
    "    'lr_scheduler_factor': 0.1,\n",
    "    'lr_scheduler_patience': 20\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d1b13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(render_mode=None):\n",
    "    return PettingZooEnv(hanabi_v4.env(colors=2, ranks=5, players=2, hand_size=2, max_information_tokens=3,\n",
    "max_life_tokens=1, observation_type=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c14b47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents(p):\n",
    "    \n",
    "    def noisy_linear(x, y):\n",
    "        return NoisyLinear(x, y, p['noisy_std'])\n",
    "    \n",
    "    # Return Policy, Agents, Envs\n",
    "    env = get_env()\n",
    "    observation_space = env.observation_space['observation'] if isinstance(\n",
    "    env.observation_space, gym.spaces.Dict\n",
    "    ) else env.observation_space\n",
    "\n",
    "    state_shape = observation_space.shape or observation_space.n\n",
    "    action_shape = env.action_space.shape or env.action_space.n\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = Net(\n",
    "            state_shape,\n",
    "            action_shape,\n",
    "            hidden_sizes=p['hidden_layers'],\n",
    "            device = device,\n",
    "            softmax = True,\n",
    "            num_atoms = p['atom_size'],\n",
    "            dueling_param = ({\n",
    "                'linear_layer': noisy_linear\n",
    "            }, {\n",
    "                'linear_layer': noisy_linear})\n",
    "    )\n",
    "\n",
    "    optim = torch.optim.Adam(net.parameters(), lr= p['lr'], eps=p['adam_eps'])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode = 'max', factor = p['lr_scheduler_factor'],\n",
    "                                                              patience = p['lr_scheduler_patience'])\n",
    "\n",
    "    agent = RainbowPolicy(\n",
    "            net,\n",
    "            optim,\n",
    "            p['gamma'],\n",
    "            num_atoms = p['atom_size'],\n",
    "            v_min = p['vmin'],\n",
    "            v_max = p['vmax'],\n",
    "            estimation_step = p['estimation_steps'],\n",
    "            target_update_freq=p['target_update_freq']\n",
    "        ).to(device)\n",
    "\n",
    "    agents = [agent, agent]\n",
    "    policy = MultiAgentPolicyManager(agents, env)\n",
    "    agents = env.agents\n",
    "\n",
    "    train_envs = DummyVectorEnv([get_env for _ in range(p['num_train'])])\n",
    "    test_envs = DummyVectorEnv([get_env for _ in range(p['num_test'])])\n",
    "    \n",
    "    return policy, agents, train_envs, test_envs, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b396937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collectors(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    test_envs,\n",
    "    p\n",
    "):\n",
    "    \n",
    "    # Get collectors\n",
    "    train_collector = Collector(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    PrioritizedVectorReplayBuffer(p['buffer_size'], len(train_envs), alpha = 0.6, beta = 0.4, weight_norm=True),\n",
    "    exploration_noise=True)\n",
    "    \n",
    "    test_collector = Collector(policy, test_envs, exploration_noise=True)\n",
    "    \n",
    "    return train_collector, test_collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79e1b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_buffer(\n",
    "    train_collector,\n",
    "    agents,\n",
    "    policy,\n",
    "    p\n",
    "):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(1)\n",
    "    train_collector.collect(n_step = p['minimum_replay_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13665eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_policy(policy, agents, p):\n",
    "    for a in agents:\n",
    "        torch.save(policy.policies[a].state_dict(), f'{p[\"path\"]}{a}_params.pth')\n",
    "\n",
    "def save_history(history, p):\n",
    "    np.save(f'{p[\"path\"]}training_rewards.npy', np.array(history))\n",
    "    \n",
    "def change_lr(optimizer, new_lr):\n",
    "    # Run this to change the learning rate to 1e-5:\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01b85c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(iteration, p):\n",
    "    if iteration > p['eps_decay_period']:\n",
    "        return p['eps_final']\n",
    "    else:\n",
    "        gradient = (1 - p['eps_final'])/p['eps_decay_period']\n",
    "        return 1 - gradient*iteration\n",
    "        \n",
    "def set_eps(policy, agents, new_eps):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(new_eps)\n",
    "        \n",
    "def train(\n",
    "    policy,\n",
    "    train_collector,\n",
    "    test_collector,\n",
    "    agents,\n",
    "    p,\n",
    "    lr_scheduler,\n",
    "    training_history = []\n",
    "):\n",
    "\n",
    "    for i in tqdm(range(p['epochs'])):\n",
    "        \n",
    "        eps = get_eps(i, p)\n",
    "        set_eps(policy, agents, eps)\n",
    "        \n",
    "        # Collection step\n",
    "        result = train_collector.collect(n_step = p['steps_per_collect'])\n",
    "        \n",
    "        # Test Step\n",
    "        if i%p['test_frequency'] == 0:\n",
    "            set_eps(policy, agents, p['test_eps'])\n",
    "            result = test_collector.collect(n_step = p['test_steps'])\n",
    "            mean_reward = result['rews'].mean()\n",
    "            tqdm.write(str(mean_reward))\n",
    "            training_history.append(mean_reward)\n",
    "            set_eps(policy, agents, eps)\n",
    "            lr_scheduler.step(mean_reward)\n",
    "    \n",
    "        if i%p['save_frequency'] == 0:\n",
    "            save_policy(policy, agents,p)\n",
    "            save_history(training_history,p)\n",
    "            plot_and_save(training_history, p['test_frequency'],p, show = False)\n",
    "    \n",
    "        # Update step (one epoch)\n",
    "        for _ in range(p['updates_per_train']): \n",
    "            losses = policy.update(p['batch_size'], train_collector.buffer)\n",
    "    \n",
    "    plot_and_save(training_history, test_frequency)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19a19b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(training_history, test_frequency, p, save = True, show = True):\n",
    "    x = np.arange(len(training_history))\n",
    "    x *= test_frequency\n",
    "    plt.plot(x, training_history)\n",
    "    plt.title('Combined Average Score (Rainbow, 2 Color game)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Score (max 10)')\n",
    "    if save: plt.savefig(f'{p[\"path\"]}training_curve.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "def load(policy, agents, p):\n",
    "    for a in agents:\n",
    "        policy.policies[a].load_state_dict(torch.load(f'{p[\"path\"]}{a}_params.pth'))\n",
    "    his = list(np.load(f'{p[\"path\"]}training_rewards.npy'))\n",
    "    return his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdf68087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/collector.py:255: UserWarning: n_step=500 is not a multiple of #env (32), which may cause extra transitions collected into the buffer.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "policy, agents, train_envs, test_envs, lr_scheduler = get_agents(p)\n",
    "train_collector, test_collector = get_collectors(policy, train_envs, test_envs, p)\n",
    "initialize_buffer(train_collector, agents, policy, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f614d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_history = load(policy, agents,p)\n",
    "training_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c545f926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d33e3937a5423fb5b9d5415ecf8c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/collector.py:255: UserWarning: n_step=4 is not a multiple of #env (32), which may cause extra transitions collected into the buffer.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/collector.py:255: UserWarning: n_step=4 is not a multiple of #env (32), which may cause extra transitions collected into the buffer.\n",
      "  warnings.warn(\n",
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2967171717171717\n",
      "0.921875\n",
      "1.0133779264214047\n",
      "1.0501672240802675\n",
      "0.9965753424657534\n",
      "1.0203389830508474\n",
      "0.9900662251655629\n",
      "1.04\n",
      "0.9965635738831615\n",
      "1.0\n",
      "1.0\n",
      "1.0433333333333332\n",
      "0.9895104895104895\n",
      "1.0209059233449478\n",
      "1.246875\n",
      "1.1580756013745706\n",
      "1.0172413793103448\n",
      "1.4205298013245033\n",
      "1.3395638629283488\n",
      "1.4746666666666666\n",
      "1.4152744630071599\n",
      "1.70316301703163\n",
      "1.677115987460815\n",
      "1.5325581395348837\n",
      "1.7335329341317365\n",
      "1.6155555555555556\n",
      "1.8329297820823245\n",
      "1.4025974025974026\n",
      "1.7112299465240641\n",
      "1.523961661341853\n",
      "1.0171821305841924\n",
      "1.7681940700808625\n",
      "1.9390862944162437\n",
      "1.6936708860759493\n",
      "1.8058035714285714\n",
      "1.6377708978328174\n",
      "1.8386243386243386\n",
      "1.818421052631579\n",
      "1.3559322033898304\n",
      "1.7135678391959799\n",
      "1.391304347826087\n",
      "1.7557603686635945\n",
      "1.6645367412140575\n",
      "1.8115942028985508\n",
      "1.8640226628895185\n",
      "1.8918918918918919\n",
      "2.0028248587570623\n",
      "1.9835164835164836\n",
      "2.1810089020771515\n",
      "1.9586374695863746\n",
      "2.0631868131868134\n",
      "2.1440922190201728\n",
      "1.7917888563049853\n",
      "2.3382789317507418\n",
      "2.1715817694369974\n",
      "2.1910994764397906\n",
      "2.07847533632287\n",
      "2.006787330316742\n",
      "2.3678474114441417\n",
      "2.2\n",
      "2.0829596412556053\n",
      "2.1177829099307157\n",
      "2.3523316062176165\n",
      "1.995\n",
      "1.7916666666666667\n",
      "2.0082191780821916\n",
      "1.557840616966581\n",
      "2.1412037037037037\n",
      "2.1861575178997614\n",
      "2.478134110787172\n",
      "2.4456521739130435\n",
      "2.7527777777777778\n",
      "2.9146341463414633\n",
      "3.066869300911854\n",
      "2.9146005509641872\n",
      "2.9116809116809117\n",
      "3.1314984709480123\n",
      "2.897360703812317\n",
      "3.0488505747126435\n",
      "3.08955223880597\n",
      "3.155688622754491\n",
      "3.2409638554216866\n",
      "3.1797101449275362\n",
      "3.408805031446541\n",
      "3.4588607594936707\n",
      "3.4841772151898733\n",
      "3.6551724137931036\n",
      "3.889908256880734\n",
      "3.8193146417445485\n",
      "4.003058103975535\n",
      "4.08\n",
      "3.9283489096573208\n",
      "4.128526645768025\n",
      "3.911392405063291\n",
      "3.984126984126984\n",
      "4.1152647975077885\n",
      "4.183800623052959\n",
      "4.288819875776397\n",
      "4.243827160493828\n",
      "4.279874213836478\n",
      "4.333333333333333\n",
      "4.216300940438871\n",
      "4.338509316770186\n",
      "4.332298136645963\n",
      "4.277258566978193\n",
      "4.186335403726708\n",
      "4.200626959247649\n",
      "4.260869565217392\n",
      "4.326086956521739\n",
      "4.51875\n",
      "4.3734567901234565\n",
      "4.367601246105919\n",
      "4.373831775700935\n",
      "4.406832298136646\n",
      "4.439628482972136\n",
      "4.4832826747720365\n",
      "4.361370716510903\n",
      "4.4733542319749215\n",
      "4.527272727272727\n",
      "4.613003095975232\n",
      "4.6422018348623855\n",
      "4.400621118012422\n",
      "4.651090342679128\n",
      "4.593846153846154\n",
      "4.478395061728395\n",
      "4.62962962962963\n",
      "4.551829268292683\n",
      "4.598159509202454\n",
      "4.719512195121951\n",
      "4.681957186544342\n",
      "4.701492537313433\n",
      "4.807926829268292\n",
      "4.7477203647416415\n",
      "4.8343558282208585\n",
      "4.606060606060606\n",
      "4.601208459214502\n",
      "4.814024390243903\n",
      "4.780864197530864\n",
      "4.415151515151515\n",
      "4.803030303030303\n",
      "4.700934579439252\n",
      "4.766666666666667\n",
      "4.761467889908257\n",
      "4.791411042944786\n",
      "4.732732732732733\n",
      "4.7317073170731705\n",
      "4.820668693009119\n",
      "4.81039755351682\n",
      "4.834862385321101\n",
      "4.894736842105263\n",
      "4.873111782477341\n",
      "4.841317365269461\n",
      "4.4777448071216615\n",
      "4.865269461077844\n",
      "4.834834834834835\n",
      "4.908256880733945\n",
      "4.82370820668693\n",
      "4.880368098159509\n",
      "4.901840490797546\n",
      "4.777777777777778\n",
      "4.827794561933535\n",
      "4.9939024390243905\n",
      "4.953846153846154\n",
      "4.887878787878788\n",
      "4.754601226993865\n",
      "4.8942598187311175\n",
      "4.927492447129909\n",
      "4.951219512195122\n",
      "4.81981981981982\n",
      "4.606508875739645\n",
      "4.9071207430340555\n",
      "4.954682779456193\n",
      "4.9787878787878785\n",
      "4.601208459214502\n",
      "4.7907692307692304\n",
      "4.87125748502994\n",
      "4.887537993920972\n",
      "4.909090909090909\n",
      "4.837837837837838\n",
      "4.969325153374233\n",
      "4.901234567901234\n",
      "4.996951219512195\n",
      "4.900900900900901\n",
      "4.925696594427245\n",
      "4.867069486404834\n",
      "4.99388379204893\n",
      "4.919003115264798\n",
      "4.920731707317073\n",
      "4.907407407407407\n",
      "4.996978851963746\n",
      "4.8810975609756095\n",
      "4.987692307692308\n",
      "4.878048780487805\n",
      "5.042813455657492\n",
      "4.866261398176292\n",
      "5.02416918429003\n",
      "4.882175226586103\n",
      "5.0121580547112465\n",
      "4.908814589665654\n",
      "5.045454545454546\n",
      "4.944272445820434\n",
      "4.8567073170731705\n",
      "4.8932926829268295\n",
      "5.045731707317073\n",
      "4.996951219512195\n",
      "4.75748502994012\n",
      "4.876506024096385\n",
      "4.914110429447852\n",
      "4.9176829268292686\n",
      "4.920245398773006\n",
      "5.064024390243903\n",
      "4.990825688073395\n",
      "5.039039039039039\n",
      "4.889908256880734\n",
      "4.605341246290801\n",
      "5.102167182662539\n",
      "4.909365558912387\n",
      "5.105105105105105\n",
      "5.04833836858006\n",
      "5.12874251497006\n",
      "5.170731707317073\n",
      "5.036036036036036\n",
      "4.993920972644377\n",
      "5.0602409638554215\n",
      "4.862385321100917\n",
      "4.460122699386503\n",
      "4.972644376899696\n",
      "4.97583081570997\n",
      "5.159509202453988\n",
      "4.786786786786787\n",
      "5.075987841945289\n",
      "5.149390243902439\n",
      "4.954128440366972\n",
      "4.861963190184049\n",
      "5.055555555555555\n",
      "4.8969696969696965\n",
      "4.9079754601226995\n",
      "5.219512195121951\n",
      "5.018072289156627\n",
      "4.972972972972973\n",
      "5.02416918429003\n",
      "4.997005988023952\n",
      "5.11144578313253\n",
      "4.859701492537313\n",
      "5.048929663608563\n",
      "5.0602409638554215\n",
      "5.178787878787879\n",
      "4.791666666666667\n",
      "5.1871165644171775\n",
      "5.13595166163142\n",
      "5.10091743119266\n",
      "5.153614457831325\n",
      "5.180981595092025\n",
      "5.049079754601227\n",
      "4.984939759036145\n",
      "5.166666666666667\n",
      "5.074074074074074\n",
      "5.066465256797583\n",
      "5.08411214953271\n",
      "5.201834862385321\n",
      "5.206060606060606\n",
      "5.1656441717791415\n",
      "5.171779141104294\n",
      "5.1192660550458715\n",
      "5.212962962962963\n",
      "5.17629179331307\n",
      "5.1432926829268295\n",
      "5.137614678899083\n",
      "5.168711656441718\n",
      "5.252252252252252\n",
      "5.3734567901234565\n",
      "5.3373860182370825\n",
      "5.121951219512195\n",
      "5.320121951219512\n",
      "5.350609756097561\n",
      "5.1878787878787875\n",
      "5.294478527607362\n",
      "5.266666666666667\n",
      "5.133738601823708\n",
      "5.317220543806647\n",
      "5.361963190184049\n",
      "5.198170731707317\n",
      "5.108761329305136\n",
      "5.2782874617737\n",
      "5.338368580060423\n",
      "5.233128834355829\n",
      "5.1432926829268295\n",
      "5.25\n",
      "5.23404255319149\n",
      "5.3003003003003\n",
      "5.300911854103344\n",
      "5.205438066465256\n",
      "5.141566265060241\n",
      "5.220858895705521\n",
      "5.232415902140673\n",
      "5.218181818181818\n",
      "5.257575757575758\n",
      "5.224615384615385\n",
      "5.389221556886228\n",
      "5.185975609756097\n",
      "5.21580547112462\n",
      "5.2560975609756095\n",
      "5.313069908814589\n",
      "5.373088685015291\n",
      "5.373493975903615\n",
      "5.277439024390244\n",
      "5.348484848484849\n",
      "5.17737003058104\n",
      "5.377245508982036\n",
      "5.343465045592705\n",
      "5.241486068111455\n",
      "5.117469879518072\n",
      "5.198776758409786\n",
      "5.310975609756097\n",
      "5.306990881458966\n",
      "5.25\n",
      "5.37082066869301\n",
      "5.267477203647417\n",
      "5.2265861027190335\n",
      "5.11854103343465\n",
      "5.3323170731707314\n",
      "5.2439024390243905\n",
      "5.192073170731708\n",
      "5.184049079754601\n",
      "5.217125382262997\n",
      "5.241691842900302\n",
      "5.2926829268292686\n",
      "5.164634146341464\n",
      "5.3373860182370825\n",
      "5.363636363636363\n",
      "5.366666666666666\n",
      "5.225609756097561\n",
      "5.314024390243903\n",
      "5.285714285714286\n",
      "5.18960244648318\n",
      "5.253012048192771\n",
      "5.196923076923077\n",
      "5.324242424242424\n",
      "5.245454545454545\n",
      "5.182370820668693\n",
      "5.191489361702128\n",
      "5.324074074074074\n",
      "5.3202416918429005\n",
      "5.297872340425532\n",
      "5.310975609756097\n",
      "5.318042813455658\n",
      "5.279635258358662\n",
      "5.296969696969697\n",
      "5.269938650306749\n",
      "5.25531914893617\n",
      "5.2696969696969695\n",
      "5.241590214067278\n",
      "5.290519877675841\n",
      "5.268882175226586\n",
      "5.333333333333333\n",
      "5.362804878048781\n",
      "5.218844984802431\n",
      "5.326283987915408\n",
      "5.180428134556575\n",
      "5.189024390243903\n",
      "5.36060606060606\n",
      "5.097560975609756\n",
      "5.216463414634147\n",
      "5.244648318042813\n",
      "5.090361445783133\n",
      "5.190184049079755\n",
      "5.364741641337386\n",
      "5.318181818181818\n",
      "5.293577981651376\n",
      "5.217522658610272\n",
      "5.345454545454546\n",
      "5.276595744680851\n",
      "5.170212765957447\n",
      "5.304878048780488\n",
      "5.307926829268292\n",
      "5.275229357798165\n",
      "5.269113149847095\n",
      "5.329305135951661\n",
      "5.350769230769231\n",
      "5.326283987915408\n",
      "5.295731707317073\n",
      "5.36060606060606\n",
      "5.409230769230769\n",
      "5.426829268292683\n",
      "5.319148936170213\n",
      "5.2097264437689965\n",
      "5.335347432024169\n",
      "5.201219512195122\n",
      "5.361702127659575\n",
      "5.261398176291793\n",
      "5.315151515151515\n",
      "5.224615384615385\n",
      "5.290030211480363\n",
      "5.371165644171779\n",
      "5.249240121580547\n",
      "5.245454545454545\n",
      "5.293051359516617\n",
      "5.2439024390243905\n",
      "5.256880733944954\n",
      "5.219512195121951\n",
      "5.310975609756097\n",
      "5.279635258358662\n",
      "5.132132132132132\n",
      "5.2272727272727275\n",
      "5.269113149847095\n",
      "5.269938650306749\n",
      "5.3093093093093096\n",
      "5.252307692307692\n",
      "5.195121951219512\n",
      "5.289634146341464\n",
      "5.2749244712990935\n",
      "5.280487804878049\n",
      "5.329305135951661\n",
      "5.236196319018405\n",
      "5.327272727272727\n",
      "5.237082066869301\n",
      "5.201219512195122\n",
      "5.251515151515152\n",
      "5.3496932515337425\n",
      "5.3462686567164175\n",
      "5.306501547987616\n",
      "5.197568389057751\n",
      "5.234756097560975\n",
      "5.298780487804878\n",
      "5.259818731117825\n",
      "5.207951070336391\n",
      "5.266666666666667\n",
      "5.422492401215806\n",
      "5.2303030303030305\n",
      "5.317901234567901\n",
      "5.296969696969697\n",
      "5.116564417177914\n",
      "5.254545454545455\n",
      "5.249240121580547\n",
      "5.335365853658536\n",
      "5.350609756097561\n",
      "5.184848484848485\n",
      "5.294478527607362\n",
      "5.331306990881459\n",
      "5.291411042944786\n",
      "5.38622754491018\n",
      "5.322085889570552\n",
      "5.149847094801223\n",
      "5.347432024169184\n",
      "5.340425531914893\n",
      "5.290909090909091\n",
      "5.290123456790123\n",
      "5.246246246246246\n",
      "5.224924012158055\n",
      "5.228658536585366\n",
      "5.361702127659575\n",
      "5.287009063444109\n",
      "5.198776758409786\n",
      "5.299694189602446\n",
      "5.333333333333333\n",
      "5.293051359516617\n",
      "5.2097264437689965\n",
      "5.282208588957055\n",
      "5.184523809523809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.340490797546012\n",
      "5.226993865030675\n",
      "5.219512195121951\n",
      "5.382978723404255\n",
      "5.275757575757575\n",
      "5.215151515151515\n",
      "5.324159021406728\n",
      "5.288753799392097\n",
      "5.126888217522659\n",
      "5.222560975609756\n",
      "5.324159021406728\n",
      "5.234939759036145\n",
      "5.245454545454545\n",
      "5.306990881458966\n",
      "5.3689024390243905\n",
      "5.273006134969325\n",
      "5.335365853658536\n",
      "5.3003003003003\n",
      "5.300613496932515\n",
      "5.25\n",
      "5.290909090909091\n",
      "5.27355623100304\n",
      "5.296636085626911\n",
      "5.166163141993958\n",
      "5.357575757575757\n",
      "5.2926829268292686\n",
      "5.313069908814589\n",
      "5.335365853658536\n",
      "5.371951219512195\n",
      "5.265861027190332\n",
      "5.211656441717792\n",
      "5.323262839879154\n",
      "5.294478527607362\n",
      "5.327327327327327\n",
      "5.247706422018348\n",
      "5.325227963525836\n",
      "5.285276073619632\n",
      "5.334346504559271\n",
      "5.234939759036145\n",
      "5.296636085626911\n",
      "5.182926829268292\n",
      "5.287878787878788\n",
      "5.245454545454545\n",
      "5.134969325153374\n",
      "5.254545454545455\n",
      "5.317073170731708\n",
      "5.27355623100304\n",
      "5.218461538461538\n",
      "5.234756097560975\n",
      "5.278787878787878\n",
      "5.2782874617737\n",
      "5.128048780487805\n",
      "5.274390243902439\n",
      "5.295731707317073\n",
      "5.348484848484849\n",
      "5.355623100303951\n",
      "5.290909090909091\n",
      "5.230061349693251\n",
      "5.303951367781155\n",
      "5.225609756097561\n",
      "5.376899696048632\n",
      "5.244648318042813\n",
      "5.2110091743119265\n",
      "5.173252279635259\n",
      "5.277945619335347\n",
      "5.314984709480123\n",
      "5.297872340425532\n",
      "5.306990881458966\n",
      "5.279141104294479\n",
      "5.265861027190332\n",
      "5.3577981651376145\n",
      "5.210365853658536\n",
      "5.17629179331307\n",
      "5.2522796352583585\n",
      "5.304878048780488\n",
      "5.177914110429448\n",
      "5.306306306306307\n",
      "5.156923076923077\n",
      "5.316109422492401\n",
      "5.112804878048781\n",
      "5.288343558282208\n",
      "5.263636363636364\n",
      "5.195718654434251\n",
      "5.297872340425532\n",
      "5.303951367781155\n",
      "5.247706422018348\n",
      "5.218181818181818\n",
      "5.321100917431193\n",
      "5.2782874617737\n",
      "5.285714285714286\n",
      "5.271341463414634\n",
      "5.283536585365853\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_122019/3111622494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_collector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_collector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_122019/3434042788.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(policy, train_collector, test_collector, agents, p, lr_scheduler, training_history)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Update step (one epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'updates_per_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mplot_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/policy/base.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, sample_size, buffer, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_process_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/policy/multiagent/mapolicy.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/policy/modelfree/rainbow.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# so that NoisyLinear takes effect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/policy/modelfree/c51.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mtarget_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mcurr_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/policy/modelfree/c51.py\u001b[0m in \u001b[0;36m_target_dist\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"obs_next\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mnext_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model_old\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"obs_next\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"obs_next\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/policy/modelfree/dqn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, state, model, input, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mobs_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_q_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_action_num\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/utils/net/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, state, info)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mbsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_dueling\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Dueling DQN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_atoms\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_atoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/utils/net/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/utils/net/discrete.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_p\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             )\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_bias\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_bias\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(policy, train_collector, test_collector, agents, p, lr_scheduler, training_history = training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73832f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c9945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a02f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
