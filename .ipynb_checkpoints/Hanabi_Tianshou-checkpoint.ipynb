{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028dead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from pettingzoo.classic import hanabi_v4\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tianshou.data import Collector, VectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import (\n",
    "    BasePolicy,\n",
    "    DQNPolicy,\n",
    "    MultiAgentPolicyManager,\n",
    "    RandomPolicy,\n",
    ")\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils import TensorboardLogger\n",
    "from tianshou.utils.net.common import Net\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c656c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'hidden_layers': [256,256],\n",
    "    'gamma': 0.99,\n",
    "    'lr': 1e-4,\n",
    "    'target_update_freq': 100,\n",
    "    'estimation_steps': 1,\n",
    "    'num_train':50,\n",
    "    'num_test':50,\n",
    "    'buffer_size':50000,\n",
    "    'batch_size':32,\n",
    "    'steps_per_collect': 10000,\n",
    "    'updates_per_train': 300,\n",
    "    'test_steps': 50000\n",
    "    'epochs':1000,\n",
    "    'test_frequency':5,\n",
    "    'save_frequency':50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d046a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(render_mode=None):\n",
    "    return PettingZooEnv(hanabi_v4.env(colors=2, ranks=5, players=2, hand_size=4, max_information_tokens=5,\n",
    "max_life_tokens=2, observation_type=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2fd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents(\n",
    "    lr = 1e-4, \n",
    "    hidden_layers = [256, 256], \n",
    "    gamma = 0.99,\n",
    "    target_update_freq = 100, \n",
    "    estimation_steps = 1, \n",
    "    num_train = 50, \n",
    "    num_test = 50\n",
    "):\n",
    "    \n",
    "    # Return Policy, Agents, Envs\n",
    "    env = get_env()\n",
    "    observation_space = env.observation_space['observation'] if isinstance(\n",
    "    env.observation_space, gym.spaces.Dict\n",
    "    ) else env.observation_space\n",
    "\n",
    "    state_shape = observation_space.shape or observation_space.n\n",
    "    action_shape = env.action_space.shape or env.action_space.n\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    net1 = Net(\n",
    "            state_shape,\n",
    "            action_shape,\n",
    "            hidden_sizes=hidden_layers,\n",
    "            device = device).to(device)\n",
    "\n",
    "    net2 = Net(\n",
    "        state_shape,\n",
    "        action_shape,\n",
    "        hidden_sizes=hidden_layers,\n",
    "        device = device).to(device)\n",
    "\n",
    "    optim1 = torch.optim.Adam(net1.parameters(), lr= lr)\n",
    "    optim2 = torch.optim.Adam(net2.parameters(), lr = lr)\n",
    "\n",
    "    agent1 = DQNPolicy(\n",
    "            net1,\n",
    "            optim1,\n",
    "            gamma,\n",
    "            estimation_steps,\n",
    "            target_update_freq=target_update_freq\n",
    "        )\n",
    "\n",
    "    agent2 = DQNPolicy(\n",
    "            net2,\n",
    "            optim2,\n",
    "            gamma,\n",
    "            estimation_steps,\n",
    "            target_update_freq=target_update_freq\n",
    "    )\n",
    "\n",
    "    agents = [agent1, agent2]\n",
    "    policy = MultiAgentPolicyManager(agents, env)\n",
    "    agents = env.agents\n",
    "\n",
    "    train_envs = DummyVectorEnv([get_env for _ in range(num_train)])\n",
    "    test_envs = DummyVectorEnv([get_env for _ in range(num_test)])\n",
    "    \n",
    "    return policy, agents, train_envs, test_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b7e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collectors(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    test_envs,\n",
    "    buffer_size\n",
    "):\n",
    "    \n",
    "    # Get collectors\n",
    "    train_collector = Collector(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    VectorReplayBuffer(buffer_size, len(train_envs)),\n",
    "    exploration_noise=True)\n",
    "    \n",
    "    test_collector = Collector(policy, test_envs, exploration_noise=True)\n",
    "    \n",
    "    return train_collector, test_collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb983662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_buffer(\n",
    "    train_collector,\n",
    "    buffer_size,\n",
    "    agents,\n",
    "    policy,\n",
    "    eps = 0.1\n",
    "):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(1)\n",
    "    train_collector.collect(n_step = buffer_size)\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3f8b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_policy(policy, agents):\n",
    "    for a in agents:\n",
    "        torch.save(policy.policies[a].state_dict(), f'saved_data/training_group_1/{a}_params.pth')\n",
    "\n",
    "def save_history(history):\n",
    "    np.save(f'saved_data/training_group_1/training_rewards.npy', np.array(history))\n",
    "    \n",
    "def change_lr(optimizer, new_lr):\n",
    "    # Run this to change the learning rate to 1e-5:\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bc1d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    policy,\n",
    "    train_collector,\n",
    "    test_collector,\n",
    "    agents,\n",
    "    epochs=1000,\n",
    "    collection_steps_per_epoch=10000,\n",
    "    updates_per_epoch=300,\n",
    "    test_frequency=5,\n",
    "    test_steps=50000,\n",
    "    save_frequency = 50,\n",
    "    batch_size = 32,\n",
    "    eps = 0.1,\n",
    "    training_history = []\n",
    "):\n",
    "    for i in tqdm(range(epochs)):\n",
    "        \n",
    "        # Collection step\n",
    "        result = train_collector.collect(n_step = collection_steps_per_epoch)\n",
    "        \n",
    "        # Test Step\n",
    "        if i%test_frequency == 0:\n",
    "            for a in agents:\n",
    "                policy.policies[a].set_eps(0)\n",
    "            result = test_collector.collect(n_step = test_steps)\n",
    "            mean_reward = result['rews'].mean()\n",
    "            tqdm.write(str(mean_reward))\n",
    "            training_history.append(mean_reward)\n",
    "            for a in agents:\n",
    "                policy.policies[a].set_eps(eps)\n",
    "    \n",
    "        if i%save_frequency == 0:\n",
    "            save_policy(policy, agents)\n",
    "            save_history(training_history)\n",
    "\n",
    "        # Update step (one epoch)\n",
    "        for _ in range(updates_per_epoch): losses = policy.update(batch_size, train_collector.buffer)\n",
    "    \n",
    "    plot_and_save(training_history, test_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9869d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(training_history, test_frequency, save = True):\n",
    "    x = np.arange(len(training_history))\n",
    "    x *= test_frequency\n",
    "    plt.plot(x, training_history)\n",
    "    plt.title('Combined Average Score (2 player, 2 colors, 5 ranks)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Score (max 10)')\n",
    "    if save: plt.savefig(f'saved_data/training_group_1/training_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c64e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy, agents, train_envs, test_envs = get_agents(lr = 1e-5)\n",
    "train_collector, test_collector = get_collectors(policy, train_envs, test_envs, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02b2cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in agents:\n",
    "    policy.policies[a].load_state_dict(torch.load(f'saved_data/training_group_1/{a}_params.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ac50425",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = list(np.load(f'saved_data/training_group_1/training_rewards.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44a1640f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1258be297a44509aa641d1f6144de7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.83489242282507\n",
      "6.855632183908046\n",
      "6.9500924214417745\n",
      "6.886801099908341\n",
      "6.845441925034706\n",
      "6.859576427255985\n",
      "6.884579870729455\n",
      "6.897153351698806\n",
      "6.881864328564836\n",
      "6.889607390300231\n",
      "6.943093162000918\n",
      "6.9320165365181445\n",
      "6.927322907083717\n",
      "6.951724137931034\n",
      "6.939880679210647\n",
      "6.9386248269497\n",
      "6.913143382352941\n",
      "6.941095260009204\n",
      "6.932537861404314\n",
      "6.920569329660239\n",
      "6.997717937015062\n",
      "6.940421631530706\n",
      "6.949261992619927\n",
      "7.007826887661142\n",
      "6.94268684089867\n",
      "6.942439470077661\n",
      "6.912844036697248\n",
      "6.959743824336688\n",
      "7.026146788990825\n",
      "6.97157267308574\n",
      "6.9475620975161\n",
      "6.953605879650896\n",
      "6.926402943882245\n",
      "6.921739130434783\n",
      "6.984410820724438\n",
      "6.965201465201465\n",
      "6.905330882352941\n",
      "6.922191528545119\n",
      "6.952860411899313\n",
      "6.919577205882353\n",
      "6.916016521340064\n",
      "6.95970695970696\n",
      "6.903863845446182\n",
      "6.930574712643678\n",
      "6.945412844036698\n",
      "6.988532110091743\n",
      "6.970224461749885\n",
      "7.002294630564479\n",
      "7.03391384051329\n",
      "6.977064220183486\n",
      "6.9359853680841335\n",
      "7.002759889604416\n",
      "6.9775846294602015\n",
      "6.991762013729977\n",
      "6.982142857142857\n",
      "6.906752411575563\n",
      "6.944113605130554\n",
      "6.963235294117647\n",
      "6.99908466819222\n",
      "6.993144424131627\n",
      "6.905461220743461\n",
      "6.933732167510354\n",
      "6.931161083065627\n",
      "6.972056802565277\n",
      "6.976828714220809\n",
      "6.935041171088747\n",
      "6.937328453796889\n",
      "7.002735978112175\n",
      "7.014658726523133\n",
      "6.989903625516292\n",
      "7.018841911764706\n",
      "7.024323083983479\n",
      "6.996780128794848\n",
      "6.944469940339605\n",
      "6.9807516040329975\n",
      "6.94268684089867\n",
      "7.0151237396883594\n",
      "6.993583868010999\n",
      "6.975069252077562\n",
      "6.960622710622711\n",
      "6.944087992667278\n",
      "6.937271062271062\n",
      "6.95823772372648\n",
      "6.941257457549335\n",
      "7.016430853491556\n",
      "7.005952380952381\n",
      "6.966590389016019\n",
      "6.974382433668802\n",
      "6.9848762603116406\n",
      "6.968275862068966\n",
      "6.983981693363845\n",
      "6.952860411899313\n",
      "7.038003663003663\n",
      "7.021100917431193\n",
      "7.0009170105456215\n",
      "7.008196721311475\n",
      "7.007759014148791\n",
      "7.040657834627684\n",
      "6.9967786470317535\n",
      "6.944444444444445\n",
      "7.015165441176471\n",
      "7.035961272475795\n",
      "7.008679762448606\n",
      "7.059011893870083\n",
      "6.908717480602465\n",
      "6.947296058661778\n",
      "6.998616236162362\n",
      "6.984474885844749\n",
      "6.983050847457627\n",
      "7.0\n",
      "6.970682546953733\n",
      "7.010009099181073\n",
      "7.03625516291877\n",
      "6.968109339407745\n",
      "6.985818847209515\n",
      "7.007315957933242\n",
      "7.022038567493113\n",
      "7.0618181818181816\n",
      "6.9807516040329975\n",
      "7.107600732600733\n",
      "7.0353860294117645\n",
      "6.913063477460901\n",
      "7.0393953275309205\n",
      "7.012762078395625\n",
      "7.04409738171796\n",
      "7.032479414455627\n",
      "7.028453418999541\n",
      "7.0216091954022986\n",
      "7.044728434504792\n",
      "7.0133394664213435\n",
      "7.0393953275309205\n",
      "7.0564479118861865\n",
      "7.058011049723757\n",
      "7.046896551724138\n",
      "7.070935052970981\n",
      "6.987591911764706\n",
      "7.040732265446224\n",
      "7.026158788435062\n",
      "7.019178082191781\n",
      "7.016453382084095\n",
      "7.05499541704858\n",
      "7.039798719121683\n",
      "7.027548209366391\n",
      "7.031221303948577\n",
      "7.020109689213894\n",
      "7.021559633027523\n",
      "7.036288470372072\n",
      "7.075757575757576\n",
      "7.0291704649042845\n",
      "7.019143117593437\n",
      "7.039026629935721\n",
      "7.0211202938475665\n",
      "7.002748511223087\n",
      "7.060953253895509\n",
      "7.069597069597069\n",
      "7.042562929061785\n",
      "7.0087116001834024\n",
      "6.998623853211009\n",
      "6.986244841815681\n",
      "7.044292237442923\n",
      "7.033867276887872\n",
      "7.026629935720845\n",
      "7.002757352941177\n",
      "7.101190476190476\n",
      "6.977543538038497\n",
      "7.0856102003642984\n",
      "7.073482428115016\n",
      "7.022508038585209\n",
      "7.032538955087076\n",
      "7.027994492886645\n",
      "7.058661778185151\n",
      "7.02427851580394\n",
      "7.0642496558054155\n",
      "7.04626660558864\n",
      "6.990892531876138\n",
      "7.028846153846154\n",
      "7.051930147058823\n",
      "7.068949771689498\n",
      "7.074497257769653\n",
      "7.039908256880734\n",
      "6.995442114858705\n",
      "7.011926605504587\n",
      "7.080622995877233\n",
      "7.050964187327824\n",
      "6.989425287356322\n",
      "7.090950432014552\n",
      "7.063419117647059\n",
      "7.034782608695652\n",
      "7.040515653775322\n",
      "7.01640838650866\n",
      "7.069917203311867\n",
      "7.093950504124656\n",
      "7.0776297657326595\n",
      "7.037207165824529\n",
      "7.034798534798535\n",
      "7.04147465437788\n",
      "7.017003676470588\n",
      "7.055071133547499\n",
      "7.053382420616659\n",
      "7.042485153037917\n"
     ]
    }
   ],
   "source": [
    "train(policy, train_collector, test_collector, agents, updates_per_epoch = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609af32b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc1a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f632159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b8662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4041bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
