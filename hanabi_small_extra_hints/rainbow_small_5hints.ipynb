{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017a78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from pettingzoo.classic import hanabi_v4\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tianshou.data import Collector, PrioritizedVectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import (\n",
    "    BasePolicy,\n",
    "    RainbowPolicy,\n",
    "    MultiAgentPolicyManager,\n",
    "    RandomPolicy,\n",
    ")\n",
    "from tianshou.utils.net.discrete import NoisyLinear\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils import TensorboardLogger\n",
    "from tianshou.utils.net.common import Net\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of rainbow used in deepmind paper\n",
    "p = {\n",
    "    'hidden_layers': [256,256],\n",
    "    'gamma': 0.99,\n",
    "    'lr': 1e-4,\n",
    "    'target_update_freq': 500,\n",
    "    'estimation_steps': 1,\n",
    "    'num_train':32,\n",
    "    'num_test':32,\n",
    "    'buffer_size':50000,\n",
    "    'vmax':25,\n",
    "    'vmin':-25,\n",
    "    'noisy_std':0.1,\n",
    "    'atom_size':51,\n",
    "    'minimum_replay_history':512,\n",
    "    'batch_size':32,\n",
    "    'steps_per_collect': 10016,\n",
    "    'updates_per_train': 1563,\n",
    "    'test_steps': 20000,\n",
    "    'epochs':5000,\n",
    "    'eps_decay_period': 100,\n",
    "    'test_frequency': 3,\n",
    "    'test_eps': 0,\n",
    "    'save_frequency': 25,\n",
    "    'eps_final':0.05,\n",
    "    'adam_eps': 3.125e-5,\n",
    "    'path': 'results/hint5/',\n",
    "    'lr_scheduler_factor': 0.1,\n",
    "    'lr_scheduler_patience': 20\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1b13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(render_mode=None):\n",
    "    return PettingZooEnv(hanabi_v4.env(colors=2, ranks=5, players=2, hand_size=3, max_information_tokens=5,\n",
    "max_life_tokens=1, observation_type=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14b47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents(p):\n",
    "    \n",
    "    def noisy_linear(x, y):\n",
    "        return NoisyLinear(x, y, p['noisy_std'])\n",
    "    \n",
    "    # Return Policy, Agents, Envs\n",
    "    env = get_env()\n",
    "    observation_space = env.observation_space['observation'] if isinstance(\n",
    "    env.observation_space, gym.spaces.Dict\n",
    "    ) else env.observation_space\n",
    "\n",
    "    state_shape = observation_space.shape or observation_space.n\n",
    "    action_shape = env.action_space.shape or env.action_space.n\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = Net(\n",
    "            state_shape,\n",
    "            action_shape,\n",
    "            hidden_sizes=p['hidden_layers'],\n",
    "            device = device,\n",
    "            softmax = True,\n",
    "            num_atoms = p['atom_size'],\n",
    "            dueling_param = ({\n",
    "                'linear_layer': noisy_linear\n",
    "            }, {\n",
    "                'linear_layer': noisy_linear})\n",
    "    )\n",
    "\n",
    "    optim = torch.optim.Adam(net.parameters(), lr= p['lr'], eps=p['adam_eps'])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode = 'max', factor = p['lr_scheduler_factor'],\n",
    "                                                              patience = p['lr_scheduler_patience'])\n",
    "\n",
    "    agent = RainbowPolicy(\n",
    "            net,\n",
    "            optim,\n",
    "            p['gamma'],\n",
    "            num_atoms = p['atom_size'],\n",
    "            v_min = p['vmin'],\n",
    "            v_max = p['vmax'],\n",
    "            estimation_step = p['estimation_steps'],\n",
    "            target_update_freq=p['target_update_freq']\n",
    "        ).to(device)\n",
    "\n",
    "    agents = [agent, agent]\n",
    "    policy = MultiAgentPolicyManager(agents, env)\n",
    "    agents = env.agents\n",
    "\n",
    "    train_envs = DummyVectorEnv([get_env for _ in range(p['num_train'])])\n",
    "    test_envs = DummyVectorEnv([get_env for _ in range(p['num_test'])])\n",
    "    \n",
    "    return policy, agents, train_envs, test_envs, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b396937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collectors(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    test_envs,\n",
    "    p\n",
    "):\n",
    "    \n",
    "    # Get collectors\n",
    "    train_collector = Collector(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    PrioritizedVectorReplayBuffer(p['buffer_size'], len(train_envs), alpha = 0.6, beta = 0.4, weight_norm=True),\n",
    "    exploration_noise=True)\n",
    "    \n",
    "    test_collector = Collector(policy, test_envs, exploration_noise=True)\n",
    "    \n",
    "    return train_collector, test_collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e1b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_buffer(\n",
    "    train_collector,\n",
    "    agents,\n",
    "    policy,\n",
    "    p\n",
    "):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(1)\n",
    "    train_collector.collect(n_step = p['minimum_replay_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13665eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_policy(policy, agents, p):\n",
    "    for a in agents:\n",
    "        torch.save(policy.policies[a].state_dict(), f'{p[\"path\"]}{a}_params.pth')\n",
    "\n",
    "def save_history(history, p):\n",
    "    np.save(f'{p[\"path\"]}training_rewards.npy', np.array(history))\n",
    "    \n",
    "def change_lr(optimizer, new_lr):\n",
    "    # Run this to change the learning rate to 1e-5:\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b85c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(iteration, p):\n",
    "    if iteration > p['eps_decay_period']:\n",
    "        return p['eps_final']\n",
    "    else:\n",
    "        gradient = (1 - p['eps_final'])/p['eps_decay_period']\n",
    "        return 1 - gradient*iteration\n",
    "        \n",
    "def set_eps(policy, agents, new_eps):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(new_eps)\n",
    "        \n",
    "def train(\n",
    "    policy,\n",
    "    train_collector,\n",
    "    test_collector,\n",
    "    agents,\n",
    "    p,\n",
    "    lr_scheduler,\n",
    "    training_history = []\n",
    "):\n",
    "\n",
    "    for i in tqdm(range(p['epochs'])):\n",
    "        \n",
    "        eps = get_eps(i, p)\n",
    "        set_eps(policy, agents, eps)\n",
    "        \n",
    "        # Collection step\n",
    "        result = train_collector.collect(n_step = p['steps_per_collect'])\n",
    "        \n",
    "        # Test Step\n",
    "        if i%p['test_frequency'] == 0:\n",
    "            set_eps(policy, agents, p['test_eps'])\n",
    "            result = test_collector.collect(n_step = p['test_steps'])\n",
    "            mean_reward = result['rews'].mean()\n",
    "            tqdm.write(str(mean_reward))\n",
    "            training_history.append(mean_reward)\n",
    "            set_eps(policy, agents, eps)\n",
    "            lr_scheduler.step(mean_reward)\n",
    "    \n",
    "        if i%p['save_frequency'] == 0:\n",
    "            save_policy(policy, agents,p)\n",
    "            save_history(training_history,p)\n",
    "            plot_and_save(training_history, p['test_frequency'],p, show = False)\n",
    "    \n",
    "        # Update step (one epoch)\n",
    "        for _ in range(p['updates_per_train']): \n",
    "            losses = policy.update(p['batch_size'], train_collector.buffer)\n",
    "    \n",
    "    plot_and_save(training_history, test_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a19b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(training_history, test_frequency, p, save = True, show = True):\n",
    "    x = np.arange(len(training_history))\n",
    "    x *= test_frequency\n",
    "    plt.plot(x, training_history)\n",
    "    plt.title('Combined Average Score (Rainbow, 2 Color game)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Score (max 10)')\n",
    "    if save: plt.savefig(f'{p[\"path\"]}training_curve.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "def load(policy, agents, p):\n",
    "    for a in agents:\n",
    "        policy.policies[a].load_state_dict(torch.load(f'{p[\"path\"]}{a}_params.pth'))\n",
    "    his = list(np.load(f'{p[\"path\"]}training_rewards.npy'))\n",
    "    return his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf68087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n",
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "policy, agents, train_envs, test_envs, lr_scheduler = get_agents(p)\n",
    "train_collector, test_collector = get_collectors(policy, train_envs, test_envs, p)\n",
    "initialize_buffer(train_collector, agents, policy, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f614d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_history = load(policy, agents,p)\n",
    "training_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545f926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048bf270a1e14bb596977100a31fa577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0837138508371384\n",
      "0.9694041867954911\n",
      "1.047040971168437\n",
      "1.0339256865912763\n",
      "1.022047244094488\n",
      "1.0881913303437967\n",
      "1.0287539936102237\n",
      "1.1016691957511382\n",
      "1.2084592145015105\n",
      "1.3844086021505377\n",
      "1.1061806656101427\n",
      "1.5510204081632653\n",
      "1.2805049088359046\n",
      "1.4676850763807285\n",
      "0.4113821138211382\n",
      "1.5153764581124072\n",
      "1.588235294117647\n",
      "1.3176761433868973\n",
      "1.6752767527675276\n",
      "1.8218997361477574\n",
      "2.1702127659574466\n",
      "2.318620689655172\n",
      "2.0311653116531163\n",
      "2.61094674556213\n",
      "2.844\n",
      "2.937042459736457\n",
      "3.0194174757281553\n",
      "2.967236467236467\n",
      "3.3792613636363638\n",
      "3.805397727272727\n",
      "3.7241867043847243\n",
      "3.9169054441260744\n",
      "4.36441893830703\n",
      "4.395348837209302\n",
      "4.862165963431786\n",
      "4.954732510288066\n",
      "4.879616963064295\n",
      "4.949453551912568\n",
      "4.990450204638472\n",
      "5.035112359550562\n",
      "4.680794701986755\n",
      "5.161971830985915\n",
      "5.332876712328767\n",
      "5.2754820936639115\n",
      "5.0969945355191255\n",
      "5.348178137651822\n",
      "5.2405405405405405\n",
      "5.418767507002801\n",
      "5.3679114799446745\n",
      "5.458970792767733\n",
      "5.2503401360544215\n",
      "5.703755215577191\n",
      "5.677329624478443\n",
      "5.508867667121419\n",
      "5.6\n",
      "5.752762430939226\n",
      "5.721448467966574\n",
      "5.702479338842975\n",
      "5.844660194174757\n",
      "5.963276836158192\n",
      "5.71939477303989\n",
      "5.798639455782313\n",
      "5.941908713692946\n",
      "5.950138504155125\n",
      "5.5152777777777775\n",
      "5.870523415977962\n",
      "5.712328767123288\n",
      "5.889355742296919\n",
      "5.9427792915531334\n",
      "5.904033379694019\n",
      "6.04608938547486\n",
      "6.008219178082192\n",
      "5.827210884353741\n",
      "5.967966573816156\n",
      "6.260402684563759\n",
      "5.994565217391305\n",
      "6.275103163686382\n",
      "6.287292817679558\n",
      "5.868741542625169\n",
      "6.103825136612022\n",
      "6.409589041095891\n",
      "5.973972602739726\n",
      "5.8719676549865225\n",
      "6.116402116402116\n",
      "6.275033377837116\n",
      "6.410884353741497\n",
      "6.188602442333786\n",
      "6.123978201634878\n",
      "6.285714285714286\n",
      "6.232931726907631\n",
      "5.942857142857143\n",
      "6.084450402144772\n",
      "6.201634877384196\n",
      "6.409655172413793\n",
      "6.308005427408412\n",
      "6.455661664392906\n",
      "6.5109289617486334\n",
      "6.129554655870446\n",
      "6.266304347826087\n",
      "6.34375\n",
      "6.3598901098901095\n",
      "6.241286863270777\n",
      "6.5069252077562325\n",
      "6.3023255813953485\n",
      "6.1802168021680215\n",
      "6.340163934426229\n",
      "6.2942743009320905\n",
      "6.463114754098361\n",
      "6.408108108108108\n",
      "6.418826739427012\n",
      "6.443835616438356\n",
      "6.199468085106383\n",
      "6.502710027100271\n",
      "6.427397260273972\n",
      "6.5272479564032695\n",
      "6.341496598639456\n",
      "6.061728395061729\n",
      "6.389645776566757\n",
      "6.399171270718232\n",
      "6.306849315068493\n",
      "6.293478260869565\n",
      "6.467939972714871\n",
      "6.15485564304462\n",
      "6.354223433242507\n",
      "6.318120805369127\n",
      "6.404401650618982\n",
      "6.372282608695652\n",
      "6.353494623655914\n",
      "6.521857923497268\n",
      "6.280054644808743\n",
      "6.378162450066578\n",
      "6.276797829036635\n",
      "6.401907356948229\n",
      "6.59375\n",
      "6.523744911804613\n",
      "6.434547908232119\n",
      "6.347651006711409\n",
      "6.334231805929919\n",
      "6.439455782312925\n",
      "6.289972899728998\n",
      "6.455801104972376\n",
      "6.53551912568306\n",
      "6.4640434192673\n",
      "6.458503401360544\n",
      "6.497282608695652\n",
      "6.454918032786885\n",
      "6.597544338335607\n",
      "6.592692828146143\n",
      "6.432795698924731\n",
      "6.3590785907859075\n",
      "6.484646194926569\n",
      "6.540136054421769\n",
      "6.699724517906336\n",
      "6.393858477970627\n",
      "6.434491978609626\n",
      "6.628922237380627\n",
      "6.623465211459754\n",
      "6.116951379763469\n",
      "6.359145527369827\n",
      "6.6716826265389875\n",
      "6.396761133603239\n",
      "6.314591700133869\n",
      "6.6531165311653115\n",
      "6.340108401084011\n",
      "6.650406504065041\n",
      "6.502724795640327\n",
      "6.113513513513514\n",
      "6.239625167336011\n",
      "6.528455284552845\n",
      "6.555102040816327\n",
      "6.390883977900552\n",
      "6.348238482384824\n",
      "6.516260162601626\n",
      "6.36742934051144\n",
      "6.765927977839335\n",
      "6.847736625514403\n",
      "6.850480109739369\n",
      "6.890859481582537\n",
      "6.838095238095238\n",
      "6.939477303988996\n",
      "6.841095890410959\n",
      "6.878415300546448\n",
      "6.7645466847090665\n",
      "6.903532608695652\n",
      "6.871794871794871\n",
      "6.879781420765028\n",
      "6.993169398907104\n",
      "6.959294436906378\n",
      "6.904761904761905\n",
      "6.831750339213026\n",
      "6.938775510204081\n",
      "6.902472527472527\n",
      "6.863697705802969\n",
      "6.967123287671233\n",
      "6.8731241473397\n",
      "6.895095367847412\n",
      "6.959072305593452\n",
      "7.044897959183674\n",
      "6.936227951153325\n",
      "7.0040760869565215\n",
      "6.9046321525885554\n",
      "6.914402173913044\n",
      "6.850948509485095\n",
      "7.032520325203252\n",
      "7.014986376021798\n",
      "7.001358695652174\n",
      "6.90625\n",
      "6.885558583106267\n",
      "7.06639566395664\n",
      "6.930894308943089\n",
      "7.020491803278689\n",
      "7.005449591280654\n",
      "7.038147138964578\n",
      "6.968449931412894\n",
      "6.985155195681512\n",
      "7.080054274084125\n",
      "7.039509536784741\n",
      "6.910931174089069\n",
      "7.05578231292517\n",
      "7.015006821282401\n",
      "7.0190735694822886\n",
      "7.059620596205962\n",
      "7.110204081632653\n",
      "6.994550408719346\n",
      "7.016304347826087\n",
      "6.974289580514208\n",
      "7.044654939106901\n",
      "7.068119891008174\n",
      "6.998637602179836\n",
      "7.074829931972789\n",
      "6.953488372093023\n",
      "7.035470668485675\n",
      "7.0\n",
      "7.05858310626703\n",
      "7.038873994638069\n",
      "7.025920873124147\n",
      "7.132332878581173\n",
      "7.20299727520436\n",
      "7.0421768707483\n",
      "6.956580732700136\n",
      "6.995918367346939\n",
      "7.0858310626703\n",
      "6.92087312414734\n",
      "7.00958904109589\n",
      "7.097428958051421\n",
      "7.079234972677596\n",
      "7.105191256830601\n",
      "7.079019073569483\n",
      "7.1043360433604335\n",
      "7.047879616963065\n",
      "7.046008119079838\n",
      "7.096467391304348\n",
      "7.013568521031208\n",
      "7.031207598371777\n",
      "7.03551912568306\n",
      "7.077868852459017\n",
      "6.991869918699187\n",
      "6.993206521739131\n",
      "7.070844686648502\n",
      "7.062585034013606\n",
      "7.064032697547684\n",
      "7.081632653061225\n",
      "7.125675675675676\n",
      "7.114010989010989\n",
      "6.937329700272479\n",
      "7.078804347826087\n",
      "7.088676671214189\n",
      "7.054644808743169\n",
      "7.108548168249661\n",
      "7.157103825136612\n",
      "7.087193460490464\n",
      "7.046575342465753\n",
      "7.083106267029973\n",
      "7.093369418132611\n",
      "7.081967213114754\n",
      "7.052917232021709\n",
      "7.077656675749319\n",
      "7.117486338797814\n",
      "7.128378378378378\n",
      "7.156968876860622\n",
      "7.143638850889193\n",
      "7.066848567530696\n",
      "7.090163934426229\n",
      "7.1197278911564625\n",
      "7.123473541383989\n",
      "7.12059620596206\n",
      "7.042407660738714\n"
     ]
    }
   ],
   "source": [
    "train(policy, train_collector, test_collector, agents, p, lr_scheduler, training_history = training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73832f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c9945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a02f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
