{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017a78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from pettingzoo.classic import hanabi_v4\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tianshou.data import Collector, PrioritizedVectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import (\n",
    "    BasePolicy,\n",
    "    RainbowPolicy,\n",
    "    MultiAgentPolicyManager,\n",
    "    RandomPolicy,\n",
    ")\n",
    "from tianshou.utils.net.discrete import NoisyLinear\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils import TensorboardLogger\n",
    "from tianshou.utils.net.common import Net\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of rainbow used in deepmind paper\n",
    "p = {\n",
    "    'hidden_layers': [256,256],\n",
    "    'gamma': 0.99,\n",
    "    'lr': 1e-4,\n",
    "    'target_update_freq': 500,\n",
    "    'estimation_steps': 1,\n",
    "    'num_train':32,\n",
    "    'num_test':32,\n",
    "    'buffer_size':50000,\n",
    "    'vmax':25,\n",
    "    'vmin':-25,\n",
    "    'noisy_std':0.1,\n",
    "    'atom_size':51,\n",
    "    'minimum_replay_history':512,\n",
    "    'batch_size':32,\n",
    "    'steps_per_collect': 10016,\n",
    "    'updates_per_train': 1563,\n",
    "    'test_steps': 20000,\n",
    "    'epochs':5000,\n",
    "    'eps_decay_period': 100,\n",
    "    'test_frequency': 3,\n",
    "    'test_eps': 0,\n",
    "    'save_frequency': 25,\n",
    "    'eps_final':0.05,\n",
    "    'adam_eps': 3.125e-5,\n",
    "    'path': 'results/hint4/',\n",
    "    'lr_scheduler_factor': 0.1,\n",
    "    'lr_scheduler_patience': 20\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1b13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(render_mode=None):\n",
    "    return PettingZooEnv(hanabi_v4.env(colors=2, ranks=5, players=2, hand_size=4, max_information_tokens=4,\n",
    "max_life_tokens=1, observation_type=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14b47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents(p):\n",
    "    \n",
    "    def noisy_linear(x, y):\n",
    "        return NoisyLinear(x, y, p['noisy_std'])\n",
    "    \n",
    "    # Return Policy, Agents, Envs\n",
    "    env = get_env()\n",
    "    observation_space = env.observation_space['observation'] if isinstance(\n",
    "    env.observation_space, gym.spaces.Dict\n",
    "    ) else env.observation_space\n",
    "\n",
    "    state_shape = observation_space.shape or observation_space.n\n",
    "    action_shape = env.action_space.shape or env.action_space.n\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = Net(\n",
    "            state_shape,\n",
    "            action_shape,\n",
    "            hidden_sizes=p['hidden_layers'],\n",
    "            device = device,\n",
    "            softmax = True,\n",
    "            num_atoms = p['atom_size'],\n",
    "            dueling_param = ({\n",
    "                'linear_layer': noisy_linear\n",
    "            }, {\n",
    "                'linear_layer': noisy_linear})\n",
    "    )\n",
    "\n",
    "    optim = torch.optim.Adam(net.parameters(), lr= p['lr'], eps=p['adam_eps'])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode = 'max', factor = p['lr_scheduler_factor'],\n",
    "                                                              patience = p['lr_scheduler_patience'])\n",
    "\n",
    "    agent = RainbowPolicy(\n",
    "            net,\n",
    "            optim,\n",
    "            p['gamma'],\n",
    "            num_atoms = p['atom_size'],\n",
    "            v_min = p['vmin'],\n",
    "            v_max = p['vmax'],\n",
    "            estimation_step = p['estimation_steps'],\n",
    "            target_update_freq=p['target_update_freq']\n",
    "        ).to(device)\n",
    "\n",
    "    agents = [agent, agent]\n",
    "    policy = MultiAgentPolicyManager(agents, env)\n",
    "    agents = env.agents\n",
    "\n",
    "    train_envs = DummyVectorEnv([get_env for _ in range(p['num_train'])])\n",
    "    test_envs = DummyVectorEnv([get_env for _ in range(p['num_test'])])\n",
    "    \n",
    "    return policy, agents, train_envs, test_envs, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b396937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collectors(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    test_envs,\n",
    "    p\n",
    "):\n",
    "    \n",
    "    # Get collectors\n",
    "    train_collector = Collector(\n",
    "    policy,\n",
    "    train_envs,\n",
    "    PrioritizedVectorReplayBuffer(p['buffer_size'], len(train_envs), alpha = 0.6, beta = 0.4, weight_norm=True),\n",
    "    exploration_noise=True)\n",
    "    \n",
    "    test_collector = Collector(policy, test_envs, exploration_noise=True)\n",
    "    \n",
    "    return train_collector, test_collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e1b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_buffer(\n",
    "    train_collector,\n",
    "    agents,\n",
    "    policy,\n",
    "    p\n",
    "):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(1)\n",
    "    train_collector.collect(n_step = p['minimum_replay_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13665eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_policy(policy, agents, p):\n",
    "    for a in agents:\n",
    "        torch.save(policy.policies[a].state_dict(), f'{p[\"path\"]}{a}_params.pth')\n",
    "\n",
    "def save_history(history, p):\n",
    "    np.save(f'{p[\"path\"]}training_rewards.npy', np.array(history))\n",
    "    \n",
    "def change_lr(optimizer, new_lr):\n",
    "    # Run this to change the learning rate to 1e-5:\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b85c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(iteration, p):\n",
    "    if iteration > p['eps_decay_period']:\n",
    "        return p['eps_final']\n",
    "    else:\n",
    "        gradient = (1 - p['eps_final'])/p['eps_decay_period']\n",
    "        return 1 - gradient*iteration\n",
    "        \n",
    "def set_eps(policy, agents, new_eps):\n",
    "    for a in agents:\n",
    "        policy.policies[a].set_eps(new_eps)\n",
    "        \n",
    "def train(\n",
    "    policy,\n",
    "    train_collector,\n",
    "    test_collector,\n",
    "    agents,\n",
    "    p,\n",
    "    lr_scheduler,\n",
    "    training_history = []\n",
    "):\n",
    "\n",
    "    for i in tqdm(range(p['epochs'])):\n",
    "        \n",
    "        eps = get_eps(i, p)\n",
    "        set_eps(policy, agents, eps)\n",
    "        \n",
    "        # Collection step\n",
    "        result = train_collector.collect(n_step = p['steps_per_collect'])\n",
    "        \n",
    "        # Test Step\n",
    "        if i%p['test_frequency'] == 0:\n",
    "            set_eps(policy, agents, p['test_eps'])\n",
    "            result = test_collector.collect(n_step = p['test_steps'])\n",
    "            mean_reward = result['rews'].mean()\n",
    "            tqdm.write(str(mean_reward))\n",
    "            training_history.append(mean_reward)\n",
    "            set_eps(policy, agents, eps)\n",
    "            lr_scheduler.step(mean_reward)\n",
    "    \n",
    "        if i%p['save_frequency'] == 0:\n",
    "            save_policy(policy, agents,p)\n",
    "            save_history(training_history,p)\n",
    "            plot_and_save(training_history, p['test_frequency'],p, show = False)\n",
    "    \n",
    "        # Update step (one epoch)\n",
    "        for _ in range(p['updates_per_train']): \n",
    "            losses = policy.update(p['batch_size'], train_collector.buffer)\n",
    "    \n",
    "    plot_and_save(training_history, test_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a19b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(training_history, test_frequency, p, save = True, show = True):\n",
    "    x = np.arange(len(training_history))\n",
    "    x *= test_frequency\n",
    "    plt.plot(x, training_history)\n",
    "    plt.title('Combined Average Score (Rainbow, 2 Color game)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Score (max 10)')\n",
    "    if save: plt.savefig(f'{p[\"path\"]}training_curve.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "def load(policy, agents, p):\n",
    "    for a in agents:\n",
    "        policy.policies[a].load_state_dict(torch.load(f'{p[\"path\"]}{a}_params.pth'))\n",
    "    his = list(np.load(f'{p[\"path\"]}training_rewards.npy'))\n",
    "    return his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf68087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n",
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "policy, agents, train_envs, test_envs, lr_scheduler = get_agents(p)\n",
    "train_collector, test_collector = get_collectors(policy, train_envs, test_envs, p)\n",
    "initialize_buffer(train_collector, agents, policy, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f614d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_history = load(policy, agents,p)\n",
    "training_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c545f926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bace36ef0bd43cca8382079dd095687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04964990451941439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cfs/mh2004/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py:546: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891156462585034\n",
      "1.0\n",
      "1.0122282608695652\n",
      "0.9972677595628415\n",
      "0.21774193548387097\n",
      "1.0895140664961638\n",
      "0.8256880733944955\n",
      "1.0080106809078773\n",
      "0.7837465564738292\n",
      "0.4503225806451613\n",
      "0.5569948186528497\n",
      "1.2129186602870814\n",
      "1.2564705882352942\n",
      "1.2269874476987448\n",
      "1.4373795761078998\n",
      "1.4890371782650142\n",
      "1.6306878306878307\n",
      "1.3450439146800501\n",
      "1.3693239152371341\n",
      "1.2288242730720607\n",
      "1.544186046511628\n",
      "1.6114942528735632\n",
      "1.8454842219804135\n",
      "2.025912838633687\n",
      "1.8106951871657755\n",
      "2.022222222222222\n",
      "2.2613365155131264\n",
      "2.4282238442822384\n",
      "2.579136690647482\n",
      "2.875609756097561\n",
      "2.82950423216445\n",
      "3.1587708066581306\n",
      "2.970731707317073\n",
      "3.3175182481751824\n",
      "3.8796068796068797\n",
      "4.076566125290023\n",
      "4.272401433691757\n",
      "4.379474940334129\n",
      "4.031802120141343\n",
      "4.455516014234876\n",
      "4.451276102088167\n",
      "4.376470588235295\n",
      "4.574971815107102\n",
      "3.8240190249702737\n",
      "4.726403823178017\n",
      "4.752873563218391\n",
      "4.6244292237442925\n",
      "4.9194097616345065\n",
      "4.972520908004779\n",
      "5.017045454545454\n",
      "4.555172413793104\n",
      "4.997668997668998\n",
      "5.02787456445993\n",
      "4.9640718562874255\n",
      "5.082175925925926\n",
      "4.914089347079038\n",
      "5.032407407407407\n",
      "5.0940070505287895\n",
      "5.242990654205608\n",
      "5.196511627906977\n",
      "5.089097303634232\n",
      "5.2631578947368425\n",
      "5.28125\n",
      "5.450638792102207\n",
      "5.281609195402299\n",
      "5.179606025492468\n",
      "5.284234752589183\n",
      "5.249709639953543\n",
      "5.411421911421911\n",
      "5.4218928164196125\n",
      "5.292964244521338\n",
      "5.4069898534385565\n",
      "5.473806752037253\n",
      "5.533408833522084\n",
      "5.2785388127853885\n",
      "5.776754890678942\n",
      "5.581736189402481\n",
      "5.6247139588100685\n",
      "5.737385321100917\n",
      "5.731343283582089\n",
      "5.745164960182025\n",
      "5.781714285714286\n",
      "5.789954337899544\n",
      "5.900571428571428\n",
      "5.6815578465063\n",
      "5.673012318029115\n",
      "5.918181818181818\n",
      "5.8113636363636365\n",
      "6.0353881278538815\n",
      "5.927502876869966\n",
      "5.829545454545454\n",
      "5.702031602708804\n",
      "5.995449374288965\n",
      "5.667042889390519\n",
      "5.938215102974828\n",
      "5.825938566552901\n",
      "5.865603644646924\n",
      "5.903448275862069\n",
      "5.827625570776256\n",
      "5.879368658399098\n",
      "5.9296254256526675\n",
      "6.021517553793885\n",
      "5.927601809954751\n",
      "6.029782359679267\n",
      "6.15922107674685\n",
      "5.909297052154195\n",
      "6.067599067599067\n",
      "6.083524027459954\n",
      "6.013824884792626\n",
      "5.720524017467249\n",
      "5.918181818181818\n",
      "6.013590033975085\n",
      "5.824858757062147\n",
      "6.215028901734104\n",
      "5.869614512471656\n",
      "6.1244292237442925\n",
      "5.994337485843714\n",
      "6.138728323699422\n",
      "6.117919075144509\n",
      "6.160550458715596\n",
      "6.25776754890679\n",
      "6.261467889908257\n",
      "6.265046296296297\n",
      "6.144\n",
      "5.931972789115647\n",
      "6.253378378378378\n",
      "6.315789473684211\n",
      "6.250863060989643\n",
      "6.136\n",
      "5.952542372881356\n",
      "6.279445727482679\n",
      "6.248\n",
      "6.1911935110081115\n",
      "6.117514124293785\n",
      "6.113013698630137\n",
      "6.296678121420389\n",
      "6.128735632183908\n",
      "6.204597701149425\n",
      "6.097142857142857\n",
      "6.1312785388127855\n",
      "6.191873589164786\n",
      "6.223489167616876\n",
      "6.382252559726963\n",
      "6.007882882882883\n",
      "6.303370786516854\n",
      "6.052213393870602\n",
      "6.258542141230068\n",
      "6.382929642445213\n",
      "6.118701007838745\n",
      "6.434881087202718\n",
      "6.439684329199549\n",
      "6.302721088435374\n",
      "6.145620022753128\n",
      "6.3508968609865475\n",
      "6.394796380090498\n",
      "6.287514318442153\n",
      "6.381114903299204\n",
      "6.482915717539863\n",
      "6.27891156462585\n",
      "6.218325791855204\n",
      "6.2836484983314795\n",
      "6.344671201814059\n",
      "6.259977194982897\n",
      "6.3047404063205414\n",
      "6.281321184510251\n",
      "6.410714285714286\n",
      "6.078828828828829\n",
      "6.486796785304248\n",
      "6.248306997742664\n",
      "6.070615034168565\n",
      "6.331088664421998\n",
      "6.446590909090909\n",
      "6.216704288939052\n",
      "6.307780320366133\n",
      "6.4377828054298645\n",
      "6.512994350282486\n",
      "6.598863636363636\n",
      "6.3382187147688835\n",
      "6.560364464692483\n",
      "6.530751708428246\n",
      "6.318029115341545\n",
      "6.302455357142857\n",
      "6.316798196166855\n",
      "6.305239179954442\n",
      "6.488662131519274\n",
      "6.395480225988701\n",
      "6.447219069239501\n",
      "6.557339449541284\n",
      "6.469066366704162\n",
      "6.54524627720504\n",
      "6.356179775280899\n",
      "6.5125284738041005\n",
      "6.437428243398393\n",
      "6.315789473684211\n",
      "6.597740112994351\n",
      "6.381818181818182\n",
      "6.504484304932736\n",
      "6.5390713476783695\n",
      "6.752293577981652\n",
      "6.818807339449541\n",
      "6.849829351535837\n",
      "6.811858608893957\n",
      "6.848797250859106\n",
      "6.728717366628831\n",
      "6.832764505119454\n",
      "6.7972665148063784\n",
      "6.744851258581236\n",
      "6.849829351535837\n",
      "6.8687214611872145\n",
      "6.869762174405436\n",
      "6.7534246575342465\n",
      "6.915813424345847\n",
      "6.905574516496018\n",
      "6.827664399092971\n",
      "6.845022624434389\n",
      "6.8929384965831435\n",
      "6.886363636363637\n",
      "6.799323562570462\n",
      "6.885057471264368\n",
      "6.825198637911464\n",
      "6.942594718714122\n",
      "6.818799546998868\n",
      "6.9125\n",
      "6.930839002267573\n",
      "6.79498861047836\n",
      "6.964530892448512\n",
      "6.902137232845894\n",
      "6.9737742303306725\n",
      "6.896118721461187\n",
      "7.006802721088436\n",
      "6.8715909090909095\n",
      "7.017221584385764\n",
      "6.893905191873589\n",
      "6.935558112773303\n",
      "6.901472253680634\n",
      "6.946651532349603\n",
      "7.027428571428572\n",
      "6.8875\n",
      "6.943181818181818\n",
      "6.863013698630137\n",
      "6.976109215017065\n",
      "6.924657534246576\n",
      "6.907954545454546\n",
      "6.968253968253968\n",
      "6.958997722095672\n",
      "6.97945205479452\n",
      "6.981797497155859\n",
      "6.892045454545454\n",
      "6.970454545454546\n",
      "6.937428896473265\n",
      "6.930839002267573\n",
      "6.864464692482915\n",
      "6.936291240045506\n",
      "6.968036529680365\n",
      "6.935227272727273\n",
      "6.906178489702517\n",
      "6.911161731207289\n",
      "6.976054732041049\n",
      "7.014789533560864\n",
      "6.9714611872146115\n",
      "7.018369690011481\n",
      "7.031818181818182\n",
      "6.994318181818182\n",
      "6.945205479452055\n",
      "7.011428571428572\n",
      "7.025\n",
      "6.997716894977169\n",
      "7.054794520547945\n",
      "7.025028441410694\n",
      "6.984036488027366\n",
      "7.052332195676906\n",
      "7.034403669724771\n",
      "7.043181818181818\n",
      "6.9988636363636365\n",
      "7.014806378132119\n",
      "6.993150684931507\n",
      "7.063781321184511\n",
      "7.0226500566251415\n",
      "7.064772727272727\n",
      "7.070534698521047\n",
      "7.088535754824064\n",
      "6.958049886621315\n",
      "6.952\n",
      "7.057954545454545\n",
      "7.055618615209989\n",
      "7.054421768707483\n",
      "7.039592760180995\n",
      "7.070857142857143\n",
      "6.9874715261958995\n",
      "6.9840728100113765\n",
      "7.01131221719457\n",
      "7.011363636363637\n",
      "7.050285714285715\n",
      "6.9840728100113765\n",
      "7.063926940639269\n",
      "6.9363636363636365\n",
      "7.053714285714285\n",
      "7.051136363636363\n",
      "6.97155858930603\n",
      "7.021689497716895\n",
      "7.0829545454545455\n",
      "6.997722095671982\n",
      "6.935005701254276\n",
      "7.057823129251701\n",
      "6.997711670480549\n",
      "6.990909090909091\n",
      "7.014772727272727\n",
      "7.045714285714285\n",
      "7.075428571428572\n",
      "7.039908779931585\n",
      "7.03872437357631\n",
      "7.053775743707094\n",
      "6.9875\n",
      "7.077360637087599\n",
      "7.1082004555808656\n",
      "7.022779043280182\n",
      "7.013636363636364\n",
      "7.0580865603644645\n",
      "7.07630979498861\n",
      "7.095346197502837\n",
      "7.045662100456621\n",
      "7.0693970420932875\n",
      "7.063926940639269\n",
      "6.949828962371722\n",
      "7.035187287173667\n",
      "7.103092783505154\n",
      "7.104426787741203\n",
      "7.022805017103763\n",
      "6.9863325740318905\n",
      "7.095074455899198\n",
      "7.077272727272727\n",
      "7.083428571428572\n",
      "7.060364464692483\n",
      "7.058219178082192\n",
      "7.043428571428572\n",
      "7.028409090909091\n",
      "7.015945330296128\n",
      "7.085812356979405\n",
      "7.027241770715096\n",
      "7.026166097838453\n",
      "7.050113895216401\n",
      "7.091220068415051\n",
      "7.0365714285714285\n",
      "7.069239500567537\n",
      "7.040091638029782\n",
      "7.014823261117446\n",
      "7.055618615209989\n",
      "7.1312785388127855\n",
      "7.053409090909091\n",
      "7.04\n",
      "7.030751708428246\n",
      "7.045610034207526\n",
      "7.017045454545454\n",
      "7.056818181818182\n",
      "7.030821917808219\n",
      "6.945392491467577\n",
      "7.020524515393387\n",
      "7.010297482837529\n",
      "7.139931740614334\n",
      "6.981735159817352\n",
      "7.102389078498294\n",
      "7.007963594994312\n",
      "6.993111366245695\n",
      "6.9875\n",
      "7.014823261117446\n",
      "7.044520547945205\n",
      "7.0376282782212085\n",
      "7.077010192525481\n",
      "7.030821917808219\n",
      "7.012471655328798\n",
      "7.104\n",
      "7.037542662116041\n",
      "7.0125427594070695\n",
      "6.969142857142857\n",
      "7.103644646924829\n",
      "7.016018306636155\n",
      "7.009111617312073\n",
      "7.015963511972634\n",
      "7.028409090909091\n",
      "7.052154195011338\n",
      "7.078857142857143\n",
      "7.070215175537939\n",
      "6.994285714285715\n",
      "7.052272727272728\n",
      "6.98175598631699\n",
      "6.9528735632183905\n",
      "7.054607508532423\n",
      "7.076222980659841\n",
      "7.056947608200455\n",
      "6.9977324263038545\n",
      "7.005701254275941\n",
      "7.1125\n",
      "7.140571428571429\n",
      "7.051977401129943\n",
      "7.04\n",
      "6.996571428571428\n",
      "7.0011402508551885\n",
      "7.00907029478458\n",
      "7.022805017103763\n",
      "7.017084282460137\n",
      "7.071835803876853\n",
      "7.00918484500574\n",
      "7.0227272727272725\n",
      "7.038812785388128\n",
      "7.04199772985244\n",
      "7.04643261608154\n",
      "7.01605504587156\n",
      "7.0580865603644645\n",
      "6.9806598407281\n",
      "7.020618556701031\n",
      "6.9795454545454545\n",
      "7.009111617312073\n",
      "7.0576923076923075\n",
      "7.0\n",
      "7.096\n",
      "7.075\n",
      "7.043528064146621\n",
      "6.994318181818182\n",
      "7.08997722095672\n",
      "7.026195899772209\n",
      "7.045506257110353\n",
      "7.1\n",
      "7.054794520547945\n",
      "7.0091324200913245\n",
      "7.1118721461187215\n",
      "7.003416856492027\n",
      "7.032879818594104\n",
      "6.974799541809851\n",
      "7.031963470319635\n",
      "6.974885844748859\n",
      "7.045506257110353\n",
      "7.046697038724374\n",
      "7.005701254275941\n",
      "7.11617312072893\n",
      "7.110091743119266\n",
      "6.993174061433447\n",
      "6.988597491448118\n",
      "6.996571428571428\n",
      "7.037671232876712\n",
      "6.9874715261958995\n",
      "7.045662100456621\n",
      "7.0479452054794525\n",
      "6.963344788087056\n",
      "6.9588100686498855\n",
      "6.953461975028377\n",
      "7.062857142857143\n",
      "7.0875995449374285\n",
      "7.017064846416382\n",
      "7.027241770715096\n",
      "7.072976054732041\n",
      "7.008009153318078\n",
      "7.030751708428246\n",
      "7.045454545454546\n",
      "7.043428571428572\n",
      "7.061293984108967\n",
      "7.023890784982935\n",
      "7.044368600682594\n",
      "7.036613272311213\n",
      "6.976\n",
      "7.0423340961098395\n",
      "7.068104426787741\n",
      "7.01824401368301\n",
      "7.053530751708428\n",
      "7.107551487414188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_251602/3111622494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_collector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_collector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_251602/599579738.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(policy, train_collector, test_collector, agents, p, lr_scheduler, training_history)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Update step (one epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'updates_per_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mplot_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/policy/base.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, sample_size, buffer, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/data/buffer/base.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \"\"\"\n\u001b[1;32m    314\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     def get(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/data/buffer/prio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# ref: https://github.com/Kaixhin/Rainbow/blob/master/memory.py L154\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/data/buffer/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;31m# raise KeyError first instead of AttributeError,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# to support np.array([ReplayBuffer()])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs_next\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mobs_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"obs_next\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/data/buffer/base.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, index, key, default_value, stack_num)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstack_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# the most often case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mstack\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tianshou/data/batch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0mnew_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                     \u001b[0mnew_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(policy, train_collector, test_collector, agents, p, lr_scheduler, training_history = training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73832f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c9945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a02f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
